{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C3: LLM 内部机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import init_torch_device\n",
    "\n",
    "\n",
    "device = init_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104d9aacc3e8454793afd3fca091de0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device.type,\n",
    "    torch_dtype='auto',\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "generator = pipeline(\n",
    "    'text-generation',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Miyano Family: A Tale of Harmony and Joy\n",
      "\n",
      "In a world where the shadows of the black Organization no longer loomed over the city, the Miyano family found themselves basking in the warmth of a newfound peace. The once-feared criminals had vanished, leaving behind a society that was finally free to thrive.\n",
      "\n",
      "Shiho Miyano, a young woman with a heart full of hope, was at the center of this transformation. As a member of the Detective Conan team, she had played a crucial role in bringing down the black Organization and restoring harmony to the city.\n",
      "\n",
      "The Miyano family, consisting of Shiho, her parents, and her younger brother, had always been close-knit. They shared a bond that was unbreakable, and their love for each other was evident in every smile and every hug.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a noval about Miyano family from Detective Conan assuming that they are living in a world without black Organization. The main character is Shiho Miyano. The story should be happy and harmony.\"\n",
    "\n",
    "output = generator(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
